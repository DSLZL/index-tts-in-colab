{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSLZL/index-tts-in-colab/blob/main/index_tts_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 克隆源仓库(Clone the source repository)"
      ],
      "metadata": {
        "id": "E7ElfkFXtOzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/index-tts/index-tts.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ixmz4MOy24u",
        "outputId": "5d7d264f-cb82-4112-a3b3-605bf0c6d730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'index-tts'...\n",
            "remote: Enumerating objects: 450, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 450 (delta 171), reused 131 (delta 121), pack-reused 249 (from 1)\u001b[K\n",
            "Receiving objects: 100% (450/450), 1.76 MiB | 15.50 MiB/s, done.\n",
            "Resolving deltas: 100% (261/261), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安装前置(当提示需要重启时点击重启)[Install the front(When prompted to restart, click Restart)]"
      ],
      "metadata": {
        "id": "EHtCdHu5tS5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd index-tts\n",
        "!pip install -r requirements.txt\n",
        "!apt-get install ffmpeg\n",
        "!huggingface-cli download IndexTeam/Index-TTS \\\n",
        "  bigvgan_discriminator.pth bigvgan_generator.pth bpe.model dvae.pth gpt.pth unigram_12000.vocab \\\n",
        "  --local-dir checkpoints\n",
        "!pip install -e \".[webui]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VwrhVzLXy3_j",
        "outputId": "5ce31de2-d134-484c-9cd8-109ea24a1e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/index-tts\n",
            "Ignoring wetext: markers 'platform_system == \"Darwin\"' don't match your environment\n",
            "Collecting accelerate==0.25.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting transformers==4.36.2 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.15.0 (from -r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting cn2an==0.5.22 (from -r requirements.txt (line 4))\n",
            "  Downloading cn2an-0.5.22-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting ffmpeg-python==0.2.0 (from -r requirements.txt (line 5))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting Cython==3.0.7 (from -r requirements.txt (line 6))\n",
            "  Downloading Cython-3.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting g2p-en==2.1.0 (from -r requirements.txt (line 7))\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: jieba==0.42.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.42.1)\n",
            "Collecting keras==2.9.0 (from -r requirements.txt (line 9))\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting numba==0.58.1 (from -r requirements.txt (line 10))\n",
            "  Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.26.2 (from -r requirements.txt (line 11))\n",
            "  Downloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m826.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.1.3 (from -r requirements.txt (line 12))\n",
            "  Downloading pandas-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting matplotlib==3.8.2 (from -r requirements.txt (line 13))\n",
            "  Downloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting opencv-python==4.9.0.80 (from -r requirements.txt (line 14))\n",
            "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting vocos==0.1.0 (from -r requirements.txt (line 15))\n",
            "  Downloading vocos-0.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting tensorboard==2.9.1 (from -r requirements.txt (line 17))\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting omegaconf (from -r requirements.txt (line 18))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.2.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.11.0)\n",
            "Collecting gradio (from -r requirements.txt (line 21))\n",
            "  Downloading gradio-5.26.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (4.67.1)\n",
            "Collecting WeTextProcessing (from -r requirements.txt (line 24))\n",
            "  Downloading WeTextProcessing-1.0.4.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=47.3.1 in /usr/local/lib/python3.11/dist-packages (from cn2an==0.5.22->-r requirements.txt (line 4)) (75.2.0)\n",
            "Collecting proces>=0.1.3 (from cn2an==0.5.22->-r requirements.txt (line 4))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python==0.2.0->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.11/dist-packages (from g2p-en==2.1.0->-r requirements.txt (line 7)) (3.9.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from g2p-en==2.1.0->-r requirements.txt (line 7)) (7.5.0)\n",
            "Collecting distance>=0.1.3 (from g2p-en==2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba==0.58.1->-r requirements.txt (line 10))\n",
            "  Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.1.3->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.1.3->-r requirements.txt (line 12)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.1.3->-r requirements.txt (line 12)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->-r requirements.txt (line 13)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->-r requirements.txt (line 13)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->-r requirements.txt (line 13)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->-r requirements.txt (line 13)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->-r requirements.txt (line 13)) (3.2.3)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from vocos==0.1.0->-r requirements.txt (line 15)) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vocos==0.1.0->-r requirements.txt (line 15)) (1.14.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vocos==0.1.0->-r requirements.txt (line 15)) (0.8.1)\n",
            "Collecting encodec==0.1.1 (from vocos==0.1.0->-r requirements.txt (line 15))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.9.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.9.1->-r requirements.txt (line 17)) (1.71.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.9.1->-r requirements.txt (line 17)) (2.38.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard==2.9.1->-r requirements.txt (line 17))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.9.1->-r requirements.txt (line 17)) (3.8)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorboard==2.9.1->-r requirements.txt (line 17))\n",
            "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard==2.9.1->-r requirements.txt (line 17))\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard==2.9.1->-r requirements.txt (line 17))\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.9.1->-r requirements.txt (line 17)) (3.1.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.11/dist-packages (from tensorboard==2.9.1->-r requirements.txt (line 17)) (0.45.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 18))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 20)) (1.1.0)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (3.10.16)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (2.11.3)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 21)) (0.15.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 21))\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio->-r requirements.txt (line 21)) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio->-r requirements.txt (line 21)) (15.0.1)\n",
            "Collecting pynini==2.1.6 (from WeTextProcessing->-r requirements.txt (line 24))\n",
            "  Downloading pynini-2.1.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from WeTextProcessing->-r requirements.txt (line 24)) (6.5.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 21)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 17)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 17)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 17)) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1->-r requirements.txt (line 17)) (2.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 21)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 21)) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 21)) (0.14.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=0.3.1->g2p-en==2.1.0->-r requirements.txt (line 7)) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=0.3.1->g2p-en==2.1.0->-r requirements.txt (line 7)) (4.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.4->g2p-en==2.1.0->-r requirements.txt (line 7)) (8.1.8)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 20)) (4.3.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r requirements.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r requirements.txt (line 21)) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r requirements.txt (line 21)) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.1.3->-r requirements.txt (line 12)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 20)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 20)) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.25.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (13.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 20)) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.9.1->-r requirements.txt (line 17)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 21)) (0.1.2)\n",
            "Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cn2an-0.5.22-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading Cython-3.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vocos-0.1.0-py3-none-any.whl (24 kB)\n",
            "Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.26.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading WeTextProcessing-1.0.4.1-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynini-2.1.6-cp311-cp311-manylinux_2_28_x86_64.whl (154.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Building wheels for collected packages: encodec, antlr4-python3-runtime, distance\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=a98adb896371a305659cfd7e3f2e0507231ebdb450c518a087fa742afb25f66e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/a4/88/480018a664e58ca7ce6708759193ee51b017b3b72aa3df8a85\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d2165e46bce4ccd6be582a06ebfe6a68274601f678e66b97cb9506e10762662b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=818559337a0a6e14f19fb2c464f85c7e16f4c3347e55a7340ae964d8e0fc92be\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/cd/9c/3ab5d666e3bcacc58900b10959edd3816cc9557c7337986322\n",
            "Successfully built encodec antlr4-python3-runtime distance\n",
            "Installing collected packages: tensorboard-plugin-wit, pydub, keras, distance, antlr4-python3-runtime, uvicorn, tomlkit, tensorboard-data-server, semantic-version, ruff, python-multipart, pynini, protobuf, proces, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, llvmlite, groovy, ffmpy, ffmpeg-python, Cython, aiofiles, WeTextProcessing, starlette, pandas, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, cn2an, tokenizers, safehttpx, nvidia-cusolver-cu12, matplotlib, gradio-client, google-auth-oauthlib, g2p-en, fastapi, transformers, tensorboard, gradio, accelerate, encodec, vocos\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.12\n",
            "    Uninstalling Cython-3.0.12:\n",
            "      Successfully uninstalled Cython-3.0.12\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.3 which is incompatible.\n",
            "google-cloud-functions 1.20.3 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.89.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.18.0 requires keras>=3.5.0, but you have keras 2.9.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.9.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.30.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\n",
            "pandas-gbq 0.28.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.2 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "numba-cuda 0.2.0 requires numba>=0.59.1, but you have numba 0.58.1 which is incompatible.\n",
            "distributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\n",
            "google-cloud-dataproc 5.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.8 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.21.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.3 which is incompatible.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, but you have pandas 2.1.3 which is incompatible.\n",
            "dask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.70.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "cuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\n",
            "google-cloud-bigtable 2.30.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.2 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-spanner 3.53.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.20.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Cython-3.0.7 WeTextProcessing-1.0.4.1 accelerate-0.25.0 aiofiles-24.1.0 antlr4-python3-runtime-4.9.3 cn2an-0.5.22 distance-0.1.3 encodec-0.1.1 fastapi-0.115.12 ffmpeg-python-0.2.0 ffmpy-0.5.0 g2p-en-2.1.0 google-auth-oauthlib-0.4.6 gradio-5.26.0 gradio-client-1.9.0 groovy-0.1.2 keras-2.9.0 llvmlite-0.41.1 matplotlib-3.8.2 numba-0.58.1 numpy-1.26.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 opencv-python-4.9.0.80 pandas-2.1.3 proces-0.1.7 protobuf-3.19.6 pydub-0.25.1 pynini-2.1.6 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.15.0 tomlkit-0.13.2 transformers-4.36.2 uvicorn-0.34.2 vocos-0.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits",
                  "pydevd_plugins"
                ]
              },
              "id": "067f5b695b6549b28ed33d4043bbe6ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Fetching 6 files:   0% 0/6 [00:00<?, ?it/s]Downloading 'dvae.pth' to 'checkpoints/.cache/huggingface/download/Eo-uOl65TcDqOo9qbdw9EufkiwQ=.c112404dfe25d8d88084b507b0637037a419b4a5a0d9160516d9398a8f2b52c8.incomplete'\n",
            "Downloading 'gpt.pth' to 'checkpoints/.cache/huggingface/download/_7f-xidG2lZwkbGRwdGaUEGM9-w=.7797ed691d9c0295fd30af153d9ff04501e353a4c67c3f898e4b0840a5ef10dd.incomplete'\n",
            "Downloading 'bigvgan_generator.pth' to 'checkpoints/.cache/huggingface/download/T7MAeDN3QnT7K91CJaMdYrAx26o=.9ec77084929fad053355669c8b5986e32542f13afeff78ad93389a8f06ce62b0.incomplete'\n",
            "Downloading 'unigram_12000.vocab' to 'checkpoints/.cache/huggingface/download/DyI2HlpVtENU6daLhCfFZFW3_ss=.337ffb4197e69c3d7aa57efe2022bbde577b951d.incomplete'\n",
            "Downloading 'bigvgan_discriminator.pth' to 'checkpoints/.cache/huggingface/download/rP61RaCCq8JUX_UrFOklpHIyM0A=.8a11c977d56c2500c7978affd08678da7a217af124356d88010fa2abcbf51984.incomplete'\n",
            "Downloading 'bpe.model' to 'checkpoints/.cache/huggingface/download/Gxtyhw1DNb_863rgFQ-g37D7LQI=.cf30028855ff4a89f6663325c88b44a69f74f97990dd410a4b35414c4db31779.incomplete'\n",
            "\n",
            "bigvgan_generator.pth:   0% 0.00/525M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "unigram_12000.vocab:   0% 0.00/94.7k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   0% 0.00/1.63G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:   0% 0.00/243M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "unigram_12000.vocab: 100% 94.7k/94.7k [00:00<00:00, 2.73MB/s]\n",
            "Download complete. Moving file to checkpoints/unigram_12000.vocab\n",
            "\n",
            "\n",
            "bpe.model: 100% 476k/476k [00:00<00:00, 8.52MB/s]\n",
            "Download complete. Moving file to checkpoints/bpe.model\n",
            "\n",
            "bigvgan_generator.pth:   2% 10.5M/525M [00:00<00:06, 83.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   1% 10.5M/1.63G [00:00<00:24, 65.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:   4% 10.5M/243M [00:00<00:04, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:   2% 10.5M/697M [00:00<00:11, 62.3MB/s]\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:   6% 31.5M/525M [00:00<00:03, 126MB/s] \u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   1% 21.0M/1.63G [00:00<00:20, 79.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:   9% 21.0M/243M [00:00<00:02, 75.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:   3% 21.0M/697M [00:00<00:08, 79.1MB/s]\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  10% 52.4M/525M [00:00<00:03, 130MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  17% 41.9M/243M [00:00<00:02, 96.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:   6% 41.9M/697M [00:00<00:06, 94.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   3% 41.9M/1.63G [00:00<00:20, 76.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  22% 52.4M/243M [00:00<00:02, 90.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  14% 73.4M/525M [00:00<00:04, 108MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:   8% 52.4M/697M [00:00<00:07, 88.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   3% 52.4M/1.63G [00:00<00:19, 81.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  26% 62.9M/243M [00:00<00:01, 93.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   4% 62.9M/1.63G [00:00<00:18, 83.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  18% 94.4M/525M [00:00<00:03, 108MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  11% 73.4M/697M [00:00<00:06, 91.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  34% 83.9M/243M [00:00<00:01, 103MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   5% 73.4M/1.63G [00:00<00:18, 84.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  12% 83.9M/697M [00:00<00:06, 93.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  39% 94.4M/243M [00:01<00:01, 99.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   5% 83.9M/1.63G [00:01<00:18, 83.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  14% 94.4M/697M [00:01<00:06, 95.8MB/s]\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  22% 115M/525M [00:01<00:04, 98.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  43% 105M/243M [00:01<00:01, 99.0MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   6% 94.4M/1.63G [00:01<00:18, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  15% 105M/697M [00:01<00:06, 93.0MB/s] \u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  24% 126M/525M [00:01<00:04, 95.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  47% 115M/243M [00:01<00:01, 96.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   6% 105M/1.63G [00:01<00:17, 86.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  26% 136M/525M [00:01<00:04, 83.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  52% 126M/243M [00:01<00:01, 83.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  17% 115M/697M [00:01<00:07, 77.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   7% 115M/1.63G [00:01<00:19, 76.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  28% 147M/525M [00:01<00:04, 76.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  56% 136M/243M [00:01<00:01, 75.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  18% 126M/697M [00:01<00:08, 69.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   8% 126M/1.63G [00:01<00:21, 71.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  30% 157M/525M [00:01<00:04, 76.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   8% 136M/1.63G [00:01<00:19, 77.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  60% 147M/243M [00:01<00:01, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  20% 136M/697M [00:01<00:08, 62.3MB/s]\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  32% 168M/525M [00:01<00:04, 73.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  65% 157M/243M [00:01<00:01, 62.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  21% 147M/697M [00:01<00:08, 62.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:   9% 147M/1.63G [00:01<00:23, 62.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  34% 178M/525M [00:02<00:04, 70.6MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  23% 157M/697M [00:02<00:08, 63.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  69% 168M/243M [00:02<00:01, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  10% 157M/1.63G [00:02<00:23, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  36% 189M/525M [00:02<00:04, 69.5MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  24% 168M/697M [00:02<00:08, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  73% 178M/243M [00:02<00:01, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  10% 168M/1.63G [00:02<00:28, 52.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  38% 199M/525M [00:02<00:05, 58.0MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  26% 178M/697M [00:02<00:08, 58.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  78% 189M/243M [00:02<00:00, 60.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  40% 210M/525M [00:02<00:04, 64.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  12% 189M/1.63G [00:02<00:20, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  27% 189M/697M [00:02<00:07, 66.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  82% 199M/243M [00:02<00:00, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  42% 220M/525M [00:02<00:04, 71.1MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  29% 199M/697M [00:03<00:16, 30.6MB/s]\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  44% 231M/525M [00:04<00:19, 14.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  13% 210M/1.63G [00:04<01:10, 20.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  30% 210M/697M [00:04<00:30, 15.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  86% 210M/243M [00:04<00:02, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  48% 252M/525M [00:04<00:10, 25.0MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  32% 220M/697M [00:04<00:22, 21.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  14% 231M/1.63G [00:04<00:47, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  33% 231M/697M [00:04<00:16, 27.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  15% 241M/1.63G [00:05<00:41, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth:  95% 231M/243M [00:05<00:00, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  52% 273M/525M [00:05<00:07, 34.9MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  35% 241M/697M [00:05<00:13, 34.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  15% 252M/1.63G [00:05<00:35, 39.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "dvae.pth: 100% 243M/243M [00:05<00:00, 46.8MB/s]\n",
            "Download complete. Moving file to checkpoints/dvae.pth\n",
            "\n",
            "bigvgan_generator.pth:  56% 294M/525M [00:05<00:04, 46.6MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  38% 262M/697M [00:05<00:08, 50.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  17% 273M/1.63G [00:05<00:25, 53.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  60% 315M/525M [00:05<00:03, 60.0MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  41% 283M/697M [00:05<00:05, 69.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  18% 294M/1.63G [00:05<00:19, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  64% 336M/525M [00:05<00:02, 74.8MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  44% 304M/697M [00:05<00:04, 86.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  19% 315M/1.63G [00:05<00:15, 84.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  68% 357M/525M [00:05<00:02, 77.9MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  47% 325M/697M [00:05<00:04, 84.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  21% 336M/1.63G [00:05<00:15, 84.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  72% 377M/525M [00:06<00:01, 80.5MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  50% 346M/697M [00:06<00:04, 82.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  22% 357M/1.63G [00:06<00:16, 79.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  76% 398M/525M [00:06<00:01, 88.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  23% 367M/1.63G [00:06<00:15, 79.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  53% 367M/697M [00:06<00:03, 88.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  54% 377M/697M [00:06<00:03, 83.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  23% 377M/1.63G [00:06<00:16, 74.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  80% 419M/525M [00:06<00:01, 82.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  24% 388M/1.63G [00:06<00:17, 70.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  82% 430M/525M [00:06<00:01, 83.6MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  56% 388M/697M [00:06<00:04, 73.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  24% 398M/1.63G [00:06<00:16, 74.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  84% 440M/525M [00:06<00:01, 81.3MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  57% 398M/697M [00:06<00:03, 75.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  25% 409M/1.63G [00:08<01:16, 16.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  59% 409M/697M [00:08<00:16, 17.0MB/s]\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  86% 451M/525M [00:08<00:04, 18.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  26% 430M/1.63G [00:09<00:46, 25.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  90% 472M/525M [00:09<00:01, 27.6MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  62% 430M/697M [00:09<00:10, 26.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  28% 451M/1.63G [00:09<00:31, 36.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  65% 451M/697M [00:10<00:10, 23.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  28% 461M/1.63G [00:10<00:47, 24.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  68% 472M/697M [00:10<00:06, 32.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  30% 482M/1.63G [00:10<00:32, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  94% 493M/525M [00:10<00:01, 22.1MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  69% 482M/697M [00:10<00:05, 37.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  31% 503M/1.63G [00:10<00:25, 44.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  71% 493M/697M [00:10<00:04, 41.3MB/s]\u001b[A\u001b[A\n",
            "bigvgan_generator.pth:  98% 514M/525M [00:10<00:00, 29.5MB/s]\u001b[A\n",
            "bigvgan_generator.pth: 100% 524M/525M [00:10<00:00, 33.6MB/s]\u001b[A\n",
            "\n",
            "gpt.pth:  74% 514M/697M [00:10<00:03, 54.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_generator.pth: 100% 525M/525M [00:10<00:00, 48.5MB/s]\n",
            "Download complete. Moving file to checkpoints/bigvgan_generator.pth\n",
            "\n",
            "\n",
            "gpt.pth:  75% 524M/697M [00:10<00:02, 59.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  33% 535M/1.63G [00:10<00:18, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  33% 545M/1.63G [00:12<01:00, 18.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  77% 535M/697M [00:12<00:09, 16.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  35% 566M/1.63G [00:13<00:38, 27.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  80% 556M/697M [00:13<00:05, 26.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  36% 587M/1.63G [00:13<00:26, 39.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  83% 577M/697M [00:13<00:03, 38.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  37% 608M/1.63G [00:13<00:19, 52.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  86% 598M/697M [00:13<00:01, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  39% 629M/1.63G [00:13<00:15, 65.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  89% 619M/697M [00:13<00:01, 64.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  40% 650M/1.63G [00:13<00:12, 80.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  92% 640M/697M [00:13<00:00, 78.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  41% 671M/1.63G [00:13<00:10, 92.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  95% 661M/697M [00:13<00:00, 84.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  42% 692M/1.63G [00:13<00:08, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth:  98% 682M/697M [00:13<00:00, 96.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  44% 713M/1.63G [00:14<00:08, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "gpt.pth: 100% 697M/697M [00:14<00:00, 49.6MB/s]\n",
            "Download complete. Moving file to checkpoints/gpt.pth\n",
            "\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  45% 734M/1.63G [00:14<00:07, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  46% 755M/1.63G [00:14<00:06, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  48% 786M/1.63G [00:14<00:05, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  50% 807M/1.63G [00:14<00:04, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  51% 828M/1.63G [00:14<00:04, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  52% 849M/1.63G [00:14<00:04, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  53% 870M/1.63G [00:14<00:04, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  55% 891M/1.63G [00:14<00:04, 183MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  56% 912M/1.63G [00:15<00:04, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  57% 933M/1.63G [00:15<00:04, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  59% 954M/1.63G [00:15<00:03, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  60% 975M/1.63G [00:15<00:03, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  61% 996M/1.63G [00:15<00:03, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  62% 1.02G/1.63G [00:15<00:03, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  64% 1.04G/1.63G [00:15<00:03, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  65% 1.06G/1.63G [00:15<00:03, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  66% 1.08G/1.63G [00:16<00:03, 183MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  68% 1.10G/1.63G [00:16<00:02, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  69% 1.12G/1.63G [00:16<00:02, 183MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  70% 1.14G/1.63G [00:16<00:02, 189MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  72% 1.17G/1.63G [00:16<00:02, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  74% 1.21G/1.63G [00:16<00:02, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  76% 1.24G/1.63G [00:16<00:01, 204MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  77% 1.26G/1.63G [00:16<00:01, 204MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  79% 1.28G/1.63G [00:17<00:01, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  80% 1.31G/1.63G [00:17<00:01, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  82% 1.34G/1.63G [00:17<00:01, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  84% 1.37G/1.63G [00:17<00:01, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  86% 1.41G/1.63G [00:17<00:00, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  88% 1.44G/1.63G [00:17<00:00, 214MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  90% 1.47G/1.63G [00:17<00:00, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  92% 1.50G/1.63G [00:18<00:00, 210MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  94% 1.53G/1.63G [00:18<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  95% 1.55G/1.63G [00:18<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth:  97% 1.58G/1.63G [00:18<00:00, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "bigvgan_discriminator.pth: 100% 1.63G/1.63G [00:18<00:00, 87.3MB/s]\n",
            "Download complete. Moving file to checkpoints/bigvgan_discriminator.pth\n",
            "Fetching 6 files: 100% 6/6 [00:18<00:00,  3.15s/it]\n",
            "/content/index-tts/checkpoints\n",
            "Obtaining file:///content/index-tts\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers==4.36.2 in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (4.36.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (0.25.0)\n",
            "Requirement already satisfied: tokenizers==0.15.0 in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (0.15.0)\n",
            "Requirement already satisfied: einops==0.8.1 in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (0.8.1)\n",
            "Requirement already satisfied: matplotlib==3.8.2 in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (3.8.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (2.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (0.2.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (1.26.2)\n",
            "Requirement already satisfied: WeTextProcessing in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (1.0.4.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2->indextts==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers==0.15.0->indextts==0.1.1) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->indextts==0.1.1) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->indextts==0.1.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->indextts==0.1.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->indextts==0.1.1) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->indextts==0.1.1) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2->indextts==0.1.1) (4.67.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from indextts==0.1.1) (5.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->indextts==0.1.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->indextts==0.1.1) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->indextts==0.1.1) (5.9.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.9.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (1.9.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (3.10.16)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (2.1.3)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.11.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.15.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->indextts==0.1.1) (0.34.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio->indextts==0.1.1) (15.0.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->indextts==0.1.1) (1.1.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->indextts==0.1.1) (4.9.3)\n",
            "Requirement already satisfied: pynini==2.1.6 in /usr/local/lib/python3.11/dist-packages (from WeTextProcessing->indextts==0.1.1) (2.1.6)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from WeTextProcessing->indextts==0.1.1) (6.5.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->indextts==0.1.1) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->indextts==0.1.1) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->indextts==0.1.1) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->indextts==0.1.1) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->indextts==0.1.1) (0.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->indextts==0.1.1) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->indextts==0.1.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->indextts==0.1.1) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->indextts==0.1.1) (4.3.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->indextts==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->indextts==0.1.1) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->indextts==0.1.1) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.2->indextts==0.1.1) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2->indextts==0.1.1) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2->indextts==0.1.1) (2.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->indextts==0.1.1) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->indextts==0.1.1) (1.17.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->indextts==0.1.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->indextts==0.1.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->indextts==0.1.1) (13.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->indextts==0.1.1) (2.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->indextts==0.1.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->indextts==0.1.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->indextts==0.1.1) (0.1.2)\n",
            "Installing collected packages: indextts\n",
            "  Running setup.py develop for indextts\n",
            "Successfully installed indextts-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 下载模型(Download the model)"
      ],
      "metadata": {
        "id": "BQNuOdM-zNf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download IndexTeam/Index-TTS \\\n",
        "  bigvgan_discriminator.pth bigvgan_generator.pth bpe.model dvae.pth gpt.pth unigram_12000.vocab \\\n",
        "  --local-dir checkpoints\n",
        "!pip install -e \".[webui]\""
      ],
      "metadata": {
        "id": "OhUwn2Zgy3Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 启动index-tts(Start index-tts)"
      ],
      "metadata": {
        "id": "5sRaX3AkzarI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "将content/index-tts内的webui.py文件内的(Change the code in the webui.py file in content/index-tts to the bottom of the file)\n",
        "\n",
        "```\n",
        "demo.launch(server_name=\"127.0.0.1\")\n",
        "```\n",
        "改为(to)\n",
        "\n",
        "```\n",
        "demo.launch(share=True,server_name=\"127.0.0.1\")\n",
        "```"
      ],
      "metadata": {
        "id": "N1jMys8Nxx7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd index-tts\n",
        "!python webui.py"
      ],
      "metadata": {
        "id": "IyE5GFWGy_-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c787688d-5ac7-452b-8d6c-4a8fdb88da75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/index-tts\n",
            ">> GPT weights restored from: checkpoints/gpt.pth\n",
            ">> DeepSpeed加载失败，回退到标准推理: No module named 'deepspeed'\n",
            ">> Failed to load custom CUDA kernel for BigVGAN. Falling back to torch.\n",
            "Removing weight norm...\n",
            ">> bigvgan weights restored from: checkpoints/bigvgan_generator.pth\n",
            "2025-04-25 07:16:17,858 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/zh_tn_tagger.fst\n",
            "2025-04-25 07:16:17,858 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/zh_tn_verbalizer.fst\n",
            "2025-04-25 07:16:17,858 WETEXT INFO skip building fst for zh_normalizer ...\n",
            "2025-04-25 07:16:18,300 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/en_tn_tagger.fst\n",
            "2025-04-25 07:16:18,300 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/en_tn_verbalizer.fst\n",
            "2025-04-25 07:16:18,300 WETEXT INFO skip building fst for en_normalizer ...\n",
            ">> TextNormalizer loaded\n",
            "2025-04-25 07:16:19,216 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/zh_tn_tagger.fst\n",
            "2025-04-25 07:16:19,216 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/zh_tn_tagger.fst\n",
            "2025-04-25 07:16:19,216 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/zh_tn_verbalizer.fst\n",
            "2025-04-25 07:16:19,216 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/zh_tn_verbalizer.fst\n",
            "2025-04-25 07:16:19,216 WETEXT INFO skip building fst for zh_normalizer ...\n",
            "2025-04-25 07:16:19,216 WETEXT INFO skip building fst for zh_normalizer ...\n",
            "2025-04-25 07:16:19,848 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/en_tn_tagger.fst\n",
            "2025-04-25 07:16:19,848 WETEXT INFO found existing fst: /usr/local/lib/python3.11/dist-packages/tn/en_tn_tagger.fst\n",
            "2025-04-25 07:16:19,849 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/en_tn_verbalizer.fst\n",
            "2025-04-25 07:16:19,849 WETEXT INFO                     /usr/local/lib/python3.11/dist-packages/tn/en_tn_verbalizer.fst\n",
            "2025-04-25 07:16:19,849 WETEXT INFO skip building fst for en_normalizer ...\n",
            "2025-04-25 07:16:19,849 WETEXT INFO skip building fst for en_normalizer ...\n",
            ">> bpe model loaded from: checkpoints/bpe.model\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://b15e505b435d349bf2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            ">> start fast inference...\n",
            "/content/index-tts/indextts/utils/front.py:374: RuntimeWarning: The tokens length of sentence exceeds limit: 120, Tokens in sentence: ['▁', 'S', 'H', 'AND', 'ON', 'G', '▁HAS', '▁BEEN', '▁LOST', '▁WE', '▁HAVE', '▁LOST', '▁WE', \"'\", 'VE', '▁LOST', '▁COMPLETELY', '▁THE', '▁WORDS', '▁', \"'\", 'T', 'RA', 'IT', 'OR', \"'\", 'IT', \"'\", 'S', '▁VERY', '▁HEAVY', '▁MAYBE', '▁WE', '▁WILL', '▁MAKE', '▁THIS', '▁TITLE', '▁BECOME', '▁TRUE', '▁YOU', '▁AND', '▁ME', '▁WITH', '▁WHAT', '▁FACE', '▁CAN', '▁WE', '▁SHOW', '▁OUR', '▁COUNTRY', 'MEN', '▁', 'GEN', 'T', 'LE', 'MEN', '▁I', \"'\", 'M', '▁SORRY', '▁I', \"'\", 'VE', '▁B', 'UR', 'D', 'EN', 'ED', '▁YOU', '▁ALL', '▁IT', \"'\", 'S', '▁MY', '▁', 'FA', 'UL', 'T', '▁THAT', '▁MAKE', '▁YOUR', '▁', 'AR', 'C', '▁', 'DE', '▁', 'TRI', 'O', 'M', 'P', 'HE', '▁BECOME', '▁A', '▁', 'PI', 'LL', 'AR', '▁OF', '▁', 'S', 'HA', 'ME', '▁', 'S', 'I', 'R', '▁', 'X', 'ING', 'AN', 'G', '▁IS', '▁', 'CON', 'F', 'US', 'ED', '▁DIDN', \"'\", 'T', '▁WE', '▁', 'WIN', '▁', 'GER', 'MAN', 'Y', '▁WAS', '▁', 'DE', 'F', 'EAT', 'ED', '.'].Maybe unexpected behavior\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/webui.py\", line 38, in gen_single\n",
            "    output = tts.infer_fast(prompt, text, output_path) # 批次推理\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/infer.py\", line 248, in infer_fast\n",
            "    sentences = self.tokenizer.split_sentences(text_tokens_list)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 407, in split_sentences\n",
            "    return TextTokenizer.split_sentences_by_token(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  [Previous line repeated 988 more times]\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 338, in split_sentences_by_token\n",
            "    for i in range(len(tokenized_str)):\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            ">> start inference...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/webui.py\", line 36, in gen_single\n",
            "    output = tts.infer(prompt, text, output_path) # 普通推理\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/infer.py\", line 434, in infer\n",
            "    sentences = self.tokenizer.split_sentences(text_tokens_list)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 407, in split_sentences\n",
            "    return TextTokenizer.split_sentences_by_token(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  [Previous line repeated 988 more times]\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 338, in split_sentences_by_token\n",
            "    for i in range(len(tokenized_str)):\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            ">> start fast inference...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/webui.py\", line 38, in gen_single\n",
            "    output = tts.infer_fast(prompt, text, output_path) # 批次推理\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/infer.py\", line 306, in infer_fast\n",
            "    temp_codes = self.gpt.inference_speech(batch_auto_conditioning, batch_text_tokens,\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/model.py\", line 599, in inference_speech\n",
            "    speech_conditioning_latent = self.get_conditioning(speech_conditioning_latent, cond_mel_lengths)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/model.py\", line 497, in get_conditioning\n",
            "    speech_conditioning_input, mask = self.conditioning_encoder(speech_conditioning_input.transpose(1, 2),\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer_encoder.py\", line 426, in forward\n",
            "    xs, pos_emb, masks = self.embed(xs, masks)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer/subsampling.py\", line 185, in forward\n",
            "    x, pos_emb = self.pos_enc(x, offset)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer/embedding.py\", line 140, in forward\n",
            "    pos_emb = self.position_encoding(offset, x.size(1), False)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer/embedding.py\", line 97, in position_encoding\n",
            "    assert offset + size < self.max_len\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            ">> start inference...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/webui.py\", line 36, in gen_single\n",
            "    output = tts.infer(prompt, text, output_path) # 普通推理\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/infer.py\", line 474, in infer\n",
            "    codes = self.gpt.inference_speech(auto_conditioning, text_tokens,\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/model.py\", line 599, in inference_speech\n",
            "    speech_conditioning_latent = self.get_conditioning(speech_conditioning_latent, cond_mel_lengths)\n",
            "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/model.py\", line 497, in get_conditioning\n",
            "    speech_conditioning_input, mask = self.conditioning_encoder(speech_conditioning_input.transpose(1, 2),\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer_encoder.py\", line 426, in forward\n",
            "    xs, pos_emb, masks = self.embed(xs, masks)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer/subsampling.py\", line 185, in forward\n",
            "    x, pos_emb = self.pos_enc(x, offset)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer/embedding.py\", line 140, in forward\n",
            "    pos_emb = self.position_encoding(offset, x.size(1), False)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/gpt/conformer/embedding.py\", line 97, in position_encoding\n",
            "    assert offset + size < self.max_len\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            ">> start fast inference...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/webui.py\", line 38, in gen_single\n",
            "    output = tts.infer_fast(prompt, text, output_path) # 批次推理\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/infer.py\", line 248, in infer_fast\n",
            "    sentences = self.tokenizer.split_sentences(text_tokens_list)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 407, in split_sentences\n",
            "    return TextTokenizer.split_sentences_by_token(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  [Previous line repeated 988 more times]\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 338, in split_sentences_by_token\n",
            "    for i in range(len(tokenized_str)):\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            ">> start inference...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/webui.py\", line 36, in gen_single\n",
            "    output = tts.infer(prompt, text, output_path) # 普通推理\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/infer.py\", line 434, in infer\n",
            "    sentences = self.tokenizer.split_sentences(text_tokens_list)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 407, in split_sentences\n",
            "    return TextTokenizer.split_sentences_by_token(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 360, in split_sentences_by_token\n",
            "    sub_sentences = TextTokenizer.split_sentences_by_token(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  [Previous line repeated 988 more times]\n",
            "  File \"/content/index-tts/indextts/utils/front.py\", line 338, in split_sentences_by_token\n",
            "    for i in range(len(tokenized_str)):\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RecursionError: maximum recursion depth exceeded in comparison\n",
            ">> start fast inference...\n",
            "bigvgan: 100% 1/1 [00:01<00:00,  1.30s/it]\n",
            ">> Reference audio length: 59.34 seconds\n",
            ">> gpt_gen_time: 14.05 seconds\n",
            ">> gpt_forward_time: 0.18 seconds\n",
            ">> bigvgan_time: 1.30 seconds\n",
            ">> Total fast inference time: 15.80 seconds\n",
            ">> Generated audio length: 21.93 seconds\n",
            ">> [fast] bigvgan chunk_length: 1\n",
            ">> [fast] batch_num: 1 bucket_enable: True\n",
            ">> [fast] RTF: 0.7205\n",
            ">> wav file saved to: outputs/spk_1745565672.wav\n",
            ">> start fast inference...\n",
            "bigvgan: 100% 2/2 [00:01<00:00,  1.62it/s]\n",
            ">> Reference audio length: 59.34 seconds\n",
            ">> gpt_gen_time: 16.09 seconds\n",
            ">> gpt_forward_time: 0.35 seconds\n",
            ">> bigvgan_time: 0.60 seconds\n",
            ">> Total fast inference time: 17.93 seconds\n",
            ">> Generated audio length: 27.48 seconds\n",
            ">> [fast] bigvgan chunk_length: 1\n",
            ">> [fast] batch_num: 2 bucket_enable: True\n",
            ">> [fast] RTF: 0.6524\n",
            ">> wav file saved to: outputs/spk_1745565717.wav\n",
            ">> start fast inference...\n",
            "bigvgan: 100% 2/2 [00:01<00:00,  1.48it/s]\n",
            ">> Reference audio length: 59.34 seconds\n",
            ">> gpt_gen_time: 17.92 seconds\n",
            ">> gpt_forward_time: 0.35 seconds\n",
            ">> bigvgan_time: 0.65 seconds\n",
            ">> Total fast inference time: 19.88 seconds\n",
            ">> Generated audio length: 30.12 seconds\n",
            ">> [fast] bigvgan chunk_length: 1\n",
            ">> [fast] batch_num: 2 bucket_enable: True\n",
            ">> [fast] RTF: 0.6600\n",
            ">> wav file saved to: outputs/spk_1745565799.wav\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "E7ElfkFXtOzW",
        "EHtCdHu5tS5f",
        "BQNuOdM-zNf_",
        "5sRaX3AkzarI"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}